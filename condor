#!/usr/bin/env python3

import argparse
import htcondor
import os
import re
import sys

from datetime import datetime, timedelta

JobStatus = [
    "NONE",
    "IDLE",
    "RUNNING",
    "REMOVED",
    "COMPLETED",
    "HELD",
    "TRANSFERRING_OUTPUT",
    "SUSPENDED",
    "JOB_STATUS_MAX"
]

def print_help(stream=sys.stderr):
    help_msg = """Usage: {0} <object> <action> [<resource>] [<option1> <option2> ...]

"""
    stream.write(help_msg.format(sys.argv[0]))


def parse_args():

    # The only arguments that are acceptable are
    # <this> <object> <action>
    # <this> <object> <action> [<option1> <option2> ...]
    # <this> <object> <action> <resource>
    # <this> <object> <action> <resource> [<option1> <option2> ...]

    if len(sys.argv) < 3:
        print_help()
        sys.exit(1)

    parser = argparse.ArgumentParser()
    command = {}
    options = {}

    # Command arguments: up to 3 unflagged arguments at the beginning
    parser.add_argument("command", nargs="*")
    # Options arguments: optional flagged arguments following the command args
    parser.add_argument("-resource", help="Type of compute resource")

    args = parser.parse_args()

    command_object = args.command[0]
    try:
        command["object"] = command_object.lower()
    except:
        print(f"ERROR: Object must be a string")
        sys.exit(1)

    command_action = args.command[1]
    try:
        command["action"] = command_action.lower()
    except:
        print(f"ERROR: Action must be a string")
        sys.exit(1)

    if len(args.command) > 2:
        command["id"] = args.command[2]

    if args.resource is not None:
        options["resource"] = args.resource.lower()

    return {
        "command": command,
        "options": options
    }


# Retrieve the filenames of a DAGs output and event logs based on DAGMan cluster id
class DAGMan:

    @staticmethod
    def get_files(dagman_id):
    
        dag, log, out = None, None, None

        schedd = htcondor.Schedd()
        env = schedd.query(
            constraint=f"ClusterId == {dagman_id}",
            projection=["Env"],
        )
        
        if env:
            env = dict(item.split("=") for item in env[0]["Env"].split(";"))
            out = env["_CONDOR_DAGMAN_LOG"]
            log = out.replace(".dagman.out", ".nodes.log")
            dag = out.replace(".dagman.out", "")

        return dag, out, log


class Job:

    @staticmethod
    def status(id, options=None):

        job_state = "NOT SUBMITTED"
        job_started_time = None
        jobs_running = 0

        # If no resource specified, assume job is running on local pool
        if "resource" not in options:
            schedd = htcondor.Schedd()
            job = schedd.query(
                constraint=f"ClusterId == {id}",
                projection=["JobStartDate", "JobStatus"]
            )
            job_status = JobStatus[job[0]["JobStatus"]]
            print(f"Job is {job_status}", endl="")


        # Jobs running on provisioned Slurm resources need to retrieve
        # additional information from the provisioning DAGMan log
        elif options["resource"] == "slurm":

            # Variables specific to jobs running on Slurm clusters
            dagman_cluster_id = None
            provisioner_cluster_id = None
            provisioner_job_started_time = None
            slurm_cluster_id = None
            slurm_nodes_requested = None
            slurm_runtime = None

            dagman_dag, dagman_out, dagman_log = DAGMan.get_files(id)

            if dagman_dag is None:
                print(f"No Slurm jobs found for cluster ID {id}.")
                sys.exit(0)

            # Parse the .dag file to retrieve some user input values
            dagman_dag_file = open(dagman_dag, "r")
            for line in dagman_dag_file.readlines():
                if "annex_node_count =" in line:
                    slurm_nodes_requested = line.split("=")[1].strip()
                if "annex_runtime =" in line:
                    slurm_runtime = int(line.split("=")[1].strip())
            
            # Parse the DAGMan event log for useful information
            dagman_events = htcondor.JobEventLog(dagman_log)
            for event in dagman_events.events(0):
                if "LogNotes" in event.keys() and event["LogNotes"] == "DAG Node: B":
                    provisioner_cluster_id = event.cluster
                    provisioner_job_started_time = datetime.fromtimestamp(event.timestamp)
                    job_state = "PROVISIONING REQUEST PENDING"
                if "LogNotes" in event.keys() and event["LogNotes"] == "DAG Node: C":
                    slurm_cluster_id = event.cluster
                    if job_started_time is None:
                        job_started_time = datetime.fromtimestamp(event.timestamp)
                if event.cluster == slurm_cluster_id and event.type == htcondor.JobEventType.EXECUTE:
                    job_state = "RUNNING"
                    jobs_running += 1
                if event.cluster == slurm_cluster_id and event.type == htcondor.JobEventType.JOB_TERMINATED:
                    jobs_running -= 1
                    if jobs_running == 0:
                        job_state = "COMPLETE"
                if event.type == htcondor.JobEventType.JOB_HELD or event.type == htcondor.JobEventType.EXECUTABLE_ERROR:
                    job_state = "ERROR"

            # Now that we have all the information we want, display it
            current_time = datetime.now()
            time_diff = None
            if job_state is "PROVISIONING REQUEST PENDING":
                time_diff = current_time - provisioner_job_started_time
            elif job_state is "RUNNING":
                time_diff = current_time - job_started_time

            print(f"Job is {job_state}", end='')
            if time_diff is not None:
                print(f" since {round(time_diff.seconds/60)}m{(time_diff.seconds%60)}s")
            else:
                print("")


    @staticmethod
    def resources(id, options=None):

        # If no resource specified, assume job is running on local pool
        if "resource" not in options:
            schedd = htcondor.Schedd()
            job = schedd.query(
                constraint=f"ClusterId == {id}",
                projection=[""]
            )

        # Jobs running on provisioned Slurm resources need to retrieve
        # additional information from the provisioning DAGMan log
        elif options["resource"] == "slurm":

            # Internal variables
            dagman_cluster_id = None
            provisioner_cluster_id = None
            slurm_cluster_id = None
        
            # User-facing variables (all values set below are default/initial state)
            provisioner_job_started_time = None
            provisioner_job_scheduled_end_time = None
            job_state = "NOT SUBMITTED"
            job_started_time = None
            jobs_running = 0
            slurm_nodes_requested = None
            slurm_runtime = None

            dagman_dag, dagman_out, dagman_log = DAGMan.get_files(id)

            if dagman_dag is None:
                print(f"No Slurm jobs found for cluster ID {id}.")
                sys.exit(0)

            # Parse the .dag file to retrieve some user input values
            dagman_dag_file = open(dagman_dag, "r")
            for line in dagman_dag_file.readlines():
                if "annex_node_count =" in line:
                    slurm_nodes_requested = line.split("=")[1].strip()
                if "annex_runtime =" in line:
                    slurm_runtime = int(line.split("=")[1].strip())

            # Parse the DAGMan event log for useful information
            dagman_events = htcondor.JobEventLog(dagman_log)
            for event in dagman_events.events(0):
                if "LogNotes" in event.keys() and event["LogNotes"] == "DAG Node: B":
                    provisioner_cluster_id = event.cluster
                    provisioner_job_started_time = datetime.fromtimestamp(event.timestamp)
                    provisioner_job_scheduled_end_time = datetime.fromtimestamp(event.timestamp + slurm_runtime)
                    job_state = "PROVISIONING REQUEST PENDING"
                if "LogNotes" in event.keys() and event["LogNotes"] == "DAG Node: C":
                    slurm_cluster_id = event.cluster
                    if job_started_time is None:
                        job_started_time = datetime.fromtimestamp(event.timestamp)
                if event.cluster == slurm_cluster_id and event.type == htcondor.JobEventType.EXECUTE:
                    job_state = "RUNNING"
                    jobs_running += 1
                if event.cluster == slurm_cluster_id and (event.type == htcondor.JobEventType.JOB_TERMINATED or event.type == htcondor.JobEventType.JOB_EVICTED):
                    jobs_running -= 1
                    if jobs_running == 0:
                        job_state = "COMPLETE"
                if event.type == htcondor.JobEventType.JOB_HELD or event.type == htcondor.JobEventType.EXECUTABLE_ERROR:
                    job_state = "ERROR"

            # Now that we have all the information we want, display it
            if job_state is "PROVISIONING REQUEST PENDING":
                print(f"Job is still waiting for {slurm_nodes_requested} Slurm nodes to provision")
            elif job_state is "RUNNING":
                print(f"Job is running on {jobs_running}/{slurm_nodes_requested} requested Slurm nodes")
            elif job_state is "ERROR":
                print(f"An error occurred provisioning Slurm resources")

            # Show information about time remaining
            if job_state is "RUNNING" or job_state is "COMPLETE":
                current_time = datetime.now()
                if current_time < provisioner_job_scheduled_end_time:
                    time_diff = provisioner_job_scheduled_end_time - current_time
                    print(f"Slurm resources are reserved for another {round(time_diff.seconds/60)}m{(time_diff.seconds%60)}s")
                else:
                    time_diff = current_time - provisioner_job_scheduled_end_time
                    print(f"Slurm resources were terminated since {round(time_diff.seconds/60)}m{(time_diff.seconds%60)}s")


def main():

    # Parse arguments and set default values if undeclared
    try:
        args = parse_args()
    except Exception as err:
        print(f"Failed to parse arguments: {err}", file=sys.stderr)

    # Assume any error checking on the inputs happens during parsing
    command = args["command"]
    options = args["options"]

    # Figure out what the user is asking for and show it
    if command["object"] == "job":
        if command["action"] == "status":
            Job.status(command["id"], options)
        elif command["action"] == "resources":
            Job.resources(command["id"], options)

    # All done
    sys.exit(0)


if __name__ == "__main__":
    main()
